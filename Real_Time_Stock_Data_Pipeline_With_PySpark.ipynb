{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BgPqpkpz1pvV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Simulating Streaming Data with a Thread Script**"
      ],
      "metadata": {
        "id": "pK7hMoWpwfCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-11-jdk -y\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.1-bin-hadoop3.tgz\n",
        "\n",
        "!pip install -q findspark pyspark==3.5.1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DY8ieMNpWAbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lIZ5DiidTmi3"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"Real Time Stock Data Pipeline\").getOrCreate()\n",
        "\n",
        "# Define stock data schema\n",
        "schema = StructType([\n",
        "    StructField(\"timestamp\", TimestampType(), True),\n",
        "    StructField(\"stock_symbol\", StringType(), True),\n",
        "    StructField(\"open\", DoubleType(), True),\n",
        "    StructField(\"high\", DoubleType(), True),\n",
        "    StructField(\"low\", DoubleType(), True),\n",
        "    StructField(\"close\", DoubleType(), True),\n",
        "    StructField(\"volume\", IntegerType(), True)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading, time, random, csv, os\n",
        "from datetime import datetime\n",
        "\n",
        "# This global flag will control the loop\n",
        "keep_running = True\n",
        "\n",
        "def generate_stream():\n",
        "    global keep_running\n",
        "    stocks = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\"]\n",
        "    os.makedirs(\"/content/streaming_data\", exist_ok=True)\n",
        "    i = 0\n",
        "    while keep_running:  # the loop runs while this is True\n",
        "        filename = f\"/content/streaming_data/data_{i}.csv\"\n",
        "        with open(filename, \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\"timestamp\", \"stock_symbol\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
        "            now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            for s in stocks:\n",
        "                base = random.uniform(100, 300)\n",
        "                writer.writerow([\n",
        "                    now, s,\n",
        "                    round(base, 2),\n",
        "                    round(base + random.uniform(0, 5), 2),\n",
        "                    round(base - random.uniform(0, 5), 2),\n",
        "                    round(base + random.uniform(-2, 2), 2),\n",
        "                    random.randint(1000, 5000)\n",
        "                ])\n",
        "        i += 1\n",
        "        #print(f\"Wrote file {filename}\")\n",
        "        time.sleep(3)\n",
        "\n",
        "print(\"Generator function ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNaMJpqtZI9l",
        "outputId": "779f4703-5142-4494-9ade-52d57a1df692"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator function ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Start the Thread To Generate Streaming Stock Data**"
      ],
      "metadata": {
        "id": "2rQLqC9ZqO1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This begins generating data files in the background every 3 seconds."
      ],
      "metadata": {
        "id": "FjDRoA5fqRN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keep_running = True\n",
        "thread = threading.Thread(target=generate_stream, daemon=True)\n",
        "thread.start()\n",
        "print(\"Streaming started...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2li1-jWMdEUH",
        "outputId": "946f71d0-57ec-412c-cb8d-aef481c3e0ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming started...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stop/Restart the Thread**"
      ],
      "metadata": {
        "id": "4zf0zcQKqfSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if we want to stop it the thread:"
      ],
      "metadata": {
        "id": "O4VoQJYHqiX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keep_running = False\n",
        "print(\"Stopping stream...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcbI0vdrqm_E",
        "outputId": "215284c3-8da6-4673-8f1c-34d9a690b8c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping stream...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if we want to start again, just re-run:"
      ],
      "metadata": {
        "id": "ayLkcc1yqq6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keep_running = True\n",
        "thread = threading.Thread(target=generate_stream, daemon=True)\n",
        "thread.start()\n",
        "print(\"Streaming restarted...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6p4CovHqtGU",
        "outputId": "3d09699b-56eb-4d6e-d602-7f4da483d127"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming restarted...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reading Streaming Data**"
      ],
      "metadata": {
        "id": "BgPqpkpz1pvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stream = spark.readStream.format(\"csv\") \\\n",
        "    .option(\"header\", True) \\\n",
        "    .schema(schema) \\\n",
        "    .load(\"/content/streaming_data\")\n",
        "\n",
        "# Define Watermark to handle late data (delay tolerance)\n",
        "df_wk = df_stream.withWatermark(\"timestamp\", \"10 minutes\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BU-vbo4A1r6V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"isStreaming:\", df_stream.isStreaming)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SiibTLD2CV8",
        "outputId": "d9e8059a-c502-4b1e-acfa-964d4e8968cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "isStreaming: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stream.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3_AQstnhxrl",
        "outputId": "d3184d48-428a-4f30-8321-a628779f73c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- stock_symbol: string (nullable = true)\n",
            " |-- open: double (nullable = true)\n",
            " |-- high: double (nullable = true)\n",
            " |-- low: double (nullable = true)\n",
            " |-- close: double (nullable = true)\n",
            " |-- volume: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Processing data in micro-batches**"
      ],
      "metadata": {
        "id": "nD9jh-Xqxz6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, to_timestamp, abs, when\n",
        "\n",
        "# Drop rows with null essential values\n",
        "df_clean = df_wk.na.drop(subset=[\"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
        "\n",
        "# Ensure timestamp is proper\n",
        "df_clean = df_clean.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\")))\n",
        "\n",
        "# Compute price change\n",
        "df_clean = df_clean.withColumn(\"price_change\", col(\"close\") - col(\"open\"))\n",
        "\n",
        "# Detect anomalies (flag them)\n",
        "df_clean = df_clean.withColumn(\"anomaly_flag\", when(abs(col(\"price_change\")) > 5, 1).otherwise(0))\n",
        "\n",
        "# Static reference data (company names)\n",
        "company_data = [\n",
        "    (\"AAPL\", \"Apple\"),\n",
        "    (\"GOOG\", \"Google\"),\n",
        "    (\"TSLA\", \"Tesla\"),\n",
        "    (\"AMZN\", \"Amazon\"),\n",
        "    (\"MSFT\", \"Microsoft\")\n",
        "]\n",
        "company_ref = spark.createDataFrame(company_data, [\"stock_symbol\", \"company_name\"])\n",
        "\n",
        "# Join streaming data with static reference\n",
        "df_joined = df_clean.join(company_ref, on=\"stock_symbol\", how=\"left\")\n",
        "\n",
        "# Write joined results to CSV files in micro-batches\n",
        "query = df_joined.writeStream \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .format(\"csv\") \\\n",
        "    .option(\"header\", True) \\\n",
        "    .option(\"checkpointLocation\", \"/content/checkpoints/joined_stream/\") \\\n",
        "    .option(\"path\", \"/content/processed_output/\") \\\n",
        "    .trigger(processingTime=\"5 seconds\") \\\n",
        "    .start()\n",
        "\n",
        "query.awaitTermination()"
      ],
      "metadata": {
        "id": "jbjQo1-_x4JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream_path = '/content/processed_output/part-00177-790aadb8-1241-4244-9b2c-9669a107cae2-c000.csv'\n",
        "df_streaming_data = spark.read.csv(stream_path, header=True, inferSchema=True)\n",
        "df_streaming_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C636Cli9rNDx",
        "outputId": "137431fd-b8c3-450c-837a-6dc9b9fe63c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+------+------+------+------+------+--------------------+------------+------------+\n",
            "|stock_symbol|          timestamp|  open|  high|   low| close|volume|        price_change|anomaly_flag|company_name|\n",
            "+------------+-------------------+------+------+------+------+------+--------------------+------------+------------+\n",
            "|        MSFT|2025-11-09 11:29:38|258.27|258.98|255.24| 258.3|  3041| 0.03000000000002956|           0|   Microsoft|\n",
            "|        MSFT|2025-11-09 11:29:41|265.33|269.95|264.41|264.79|  1084| -0.5399999999999636|           0|   Microsoft|\n",
            "|        MSFT|2025-11-09 11:29:47|246.72|248.46|242.74|245.71|  2715|  -1.009999999999991|           0|   Microsoft|\n",
            "|        MSFT|2025-11-09 11:29:35|169.39|171.99| 168.4|169.19|  2315|-0.19999999999998863|           0|   Microsoft|\n",
            "|        MSFT|2025-11-09 11:29:44|102.76|102.98| 98.77|103.94|  3462|  1.1799999999999926|           0|   Microsoft|\n",
            "+------------+-------------------+------+------+------+------+------+--------------------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}